<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chris Warrick (Posts about Docker)</title><link>https://chriswarrick.com/</link><description></description><atom:link href="https://chriswarrick.com/blog/tags/docker.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Mon, 09 Feb 2026 21:57:07 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Deploying Python Web Applications with Docker</title><link>https://chriswarrick.com/blog/2026/02/06/deploying-python-web-applications-with-docker/</link><dc:creator>Chris Warrick</dc:creator><description>&lt;p&gt;Ten years ago, almost to the day, I wrote a very long blog post titled &lt;a href="https://chriswarrick.com/blog/2016/02/10/deploying-python-web-apps-with-nginx-and-uwsgi-emperor/"&gt;Deploying Python Web Applications with nginx and uWSGI Emperor&lt;/a&gt;. This week, I’ve migrated the Python web applications hosted on my VPS to Docker containers. Here are some reasons why, and all my Docker files to help you do this on your server.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;You can jump to the &lt;a href="https://chriswarrick.com/blog/2026/02/06/deploying-python-web-applications-with-docker/#scripts-and-configuration-files"&gt;scripts and configuration files&lt;/a&gt; if you don’t care about the theory and just want to see the end result.&lt;/p&gt;
&lt;h2&gt;Why Docker?&lt;/h2&gt;
&lt;p&gt;Docker is a technology that has taken the software engineering world by storm. The main promise is isolation: a Docker container that works on an x86_64 Linux machine will work on any x86_64 Linux machine in the same way. Want to quickly set up PostgreSQL for testing? Just run &lt;code&gt;docker run --name postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 -d --restart=unless-stopped postgres&lt;/code&gt; and wait a few seconds. Docker is great for deployment as well as production deployments, and it even supports Windows Server containers these days (whether or not this is a pleasant experience is a different question).&lt;/p&gt;
&lt;p&gt;Of course, there is a trade-off: running something in a Docker container requires more disk space than running the same software outside of Docker would. This is because Docker containers have their own copies of &lt;em&gt;everything&lt;/em&gt;: the C library, the shell, core commands, and the runtime of your favorite language. But this is not a bug, it’s a feature.&lt;/p&gt;
&lt;p&gt;If you read &lt;a href="https://chriswarrick.com/blog/2016/02/10/deploying-python-web-apps-with-nginx-and-uwsgi-emperor/"&gt;the nginx/uWSGI Emperor guide&lt;/a&gt; I wrote ten years ago, you might notice there are many cases where the configuration differs depending on the Linux distribution in use. Some distributions made logging an optional feature, others have it built in. Each distribution has a slightly different directory structure, and different users and groups for Web services. Some distros did not ship systemd service files. Red Hat is still pushing SELinux.&lt;/p&gt;
&lt;p&gt;But uWSGI is not the only pain point. There’s also the system Python. Every distribution treats it differently and applies different customizations. Arch maps &lt;code&gt;python&lt;/code&gt; to &lt;code&gt;python3&lt;/code&gt;, but other distributions do not. Arch and Fedora ship a single Python package, while Debian/Ubuntu have many split packages. Taking a dependency on the system Python also makes distro upgrades harder: if the system Python is upgraded, the virtual environment needs to be recreated. (Hope you have an up-to-date &lt;code&gt;requirements.txt&lt;/code&gt;!)&lt;/p&gt;
&lt;h2&gt;Should everything be in Docker?&lt;/h2&gt;
&lt;p&gt;It depends on your definition of &lt;em&gt;everything&lt;/em&gt;. I ended up with only one non-dockerized application (which requires access to resources that cannot easily be provided to it when it is in a container): an &lt;a href="https://dotnet.microsoft.com/en-us/apps/aspnet"&gt;ASP.NET Core&lt;/a&gt; Minimal API compiled with &lt;a href="https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/"&gt;Native AOT&lt;/a&gt;, so its maintenance burden is essentially zero. Except for that app, all web applications on my VPS, whether written in PHP, Python, or .NET, run in Docker. I don't need to figure out how to make PHP happy; I use a container image in which someone else had done the hard parts for me. I don't need to maintain Python virtual environments; they can just live inside containers. The maintenance burden for .NET is smaller, but containers still prevent issues that could be caused by removing an old version of .NET, for example. (Those apps are ASP.NET Core MVC, so they are not compatible with Native AOT.)&lt;/p&gt;
&lt;p&gt;But I am not running the Web-facing nginx instance in Docker. Similarly, I’ve kept PostgreSQL outside of Docker, and I’ve just un-dockerized a MariaDB instance. The main difference here is that I can &lt;code&gt;apt install nginx&lt;/code&gt; and get a supported and secure build, with default configuration that might be more reasonable than the default. (But then again, &lt;code&gt;apt install python3&lt;/code&gt; gets you a fairly mediocre build.)&lt;/p&gt;
&lt;p&gt;For the Python dockerization project, my requirements are fairly simple. The Docker container only needs Python, a venv with dependencies installed, and all data files of the app. The database exists outside of Docker, and I’ve already configured PostgreSQL to listen on an address accessible from within Docker (but of course, not from the public Internet). Because Django and Python have abysmal performance, static files must be served by nginx. Since I don’t want a dedicated nginx in a Docker container, the easiest solution is to mount a folder as a volume: Django runs &lt;code&gt;collectstatic&lt;/code&gt; inside the container to write static files there, and the host nginx serves them.&lt;/p&gt;
&lt;h2&gt;What should be in Docker?&lt;/h2&gt;
&lt;p&gt;There are four things that we need to put in our Docker container: Linux, Python, a venv, and a WSGI server.&lt;/p&gt;
&lt;h3&gt;Linux and Python (base image)&lt;/h3&gt;
&lt;p&gt;The choice of a base image can affect a few things about the Docker experience. For Python, the most commonly used image is the one prepared by Docker, Inc. simply named &lt;code&gt;python&lt;/code&gt;. That image has three versions, or tags in Docker parlance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;python:3.14&lt;/code&gt; (the default), which is based on Debian (1.12GB)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python:3.14-slim&lt;/code&gt;, which is based on Debian but with less cruft (119MB)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python:3.14-alpine&lt;/code&gt;, which is bvased on Alpine Linux (47.4MB)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alpine Linux images are really small, but with the caveat that they are based on the &lt;code&gt;musl&lt;/code&gt; libc instead of GNU &lt;code&gt;glibc&lt;/code&gt;, which means most binaries, including &lt;code&gt;manylinux&lt;/code&gt; binary wheels, do not work, and special builds (&lt;code&gt;musllinux&lt;/code&gt; binary wheels in this case) are required. I started with the Debian-based images (the default one for build, the slim one for production), but I switched to &lt;code&gt;python:3.14-alpine&lt;/code&gt;, as the only binary dependency I have is &lt;code&gt;psycopg2&lt;/code&gt;, which I build from source, but there are &lt;code&gt;musllinux&lt;/code&gt; wheels of &lt;code&gt;psycopg2-binary&lt;/code&gt; available.&lt;/p&gt;
&lt;h3&gt;Virtual environments and dependency management&lt;/h3&gt;
&lt;p&gt;Python packaging is still a mess. I don’t feel like using the VC-backed &lt;code&gt;uv&lt;/code&gt;, and the other big tools (like &lt;code&gt;poetry&lt;/code&gt; or &lt;code&gt;pipenv&lt;/code&gt;) introduce too much magic and bloat. All I need is a &lt;code&gt;requirements.txt&lt;/code&gt; file I can install with pip into a venv, but without having to manually track version numbers. For that, &lt;a href="https://github.com/jazzband/pip-tools"&gt;&lt;code&gt;pip-compile&lt;/code&gt; from &lt;code&gt;pip-tools&lt;/code&gt;&lt;/a&gt; is a great option. It takes a &lt;code&gt;requirements.in&lt;/code&gt; file with package names and optional version ranges, and produces a &lt;code&gt;requirements.txt&lt;/code&gt; with all dependencies (including transitive dependencies) pinned to exact versions. It doesn’t get much simpler than that.&lt;/p&gt;
&lt;p&gt;There is one issue: the &lt;code&gt;requirements.txt&lt;/code&gt; files produced by &lt;code&gt;pip-compile&lt;/code&gt; are specific to the environment in which it was executed. So if you want a &lt;code&gt;requirements.txt&lt;/code&gt; for Linux and Python 3.14, you must run &lt;code&gt;pip-compile&lt;/code&gt; on Linux with Python 3.14. While this does not matter much for this project (it has very simple dependencies), I wanted to ensure the tool runs with the same Python version the container will use, and to allow building the image without having &lt;code&gt;pip-compile&lt;/code&gt; installed on the development machine.&lt;/p&gt;
&lt;p&gt;So, I quickly hacked together a tool unoriginally named &lt;a href="https://github.com/Kwpolska/docker-pip-compile"&gt;&lt;code&gt;docker-pip-compile&lt;/code&gt;&lt;/a&gt;. It’s a five-line &lt;code&gt;Dockerfile&lt;/code&gt; and a slightly longer shell script to help run it. That way, dependencies can be updated and the entire project can be built even without a functional system Python. The only catch here (and the reason for the hackiest line in the Dockerfile) is the fact that the package must be buildable in the environment where &lt;code&gt;pip-compile&lt;/code&gt; runs, so I had to install &lt;code&gt;libpq&lt;/code&gt; (the PostgreSQL client library) there.&lt;/p&gt;
&lt;h3&gt;WSGI server&lt;/h3&gt;
&lt;p&gt;The old post used uWSGI (it’s even mentioned in the title). Sadly, &lt;a href="https://github.com/unbit/uwsgi/commit/5838086dd4490b8a55ff58fc0bf0f108caa4e079"&gt;uWSGI has been in maintenance mode since 2022&lt;/a&gt;. On the other hand, &lt;a href="https://github.com/benoitc/gunicorn"&gt;gunicorn&lt;/a&gt; is doing pretty well, so I used that. I also decided to add &lt;a href="https://uvicorn.dev/"&gt;uvicorn&lt;/a&gt; to the mix, because why not.&lt;/p&gt;
&lt;p&gt;&lt;span id="scripts-and-configuration-files"&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Scripts and configuration files&lt;/h2&gt;
&lt;p&gt;You might be able to find a more up-to-date version of those scripts in the &lt;a href="https://github.com/getnikola/nikola-users/tree/master/docker"&gt;nikola-users&lt;/a&gt; repository.&lt;/p&gt;
&lt;h3&gt;Dockerfile&lt;/h3&gt;
&lt;p&gt;The Dockerfile is pretty straightforward. To save a little disk space, I use a multi-stage build. The build stage sets up a virtual environment, installs packages into it, and copies files into &lt;code&gt;/app&lt;/code&gt;. The final stage installs &lt;code&gt;libpq&lt;/code&gt; (the PostgreSQL client library, needed for &lt;code&gt;psycopg2&lt;/code&gt;) and copies &lt;code&gt;/venv&lt;/code&gt; and &lt;code&gt;/app&lt;/code&gt; from the build stage. (The disk space savings come from not having &lt;code&gt;build-base&lt;/code&gt; and &lt;code&gt;libpq-dev&lt;/code&gt; in the final image.)&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;python:3.14-alpine&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;AS&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;build&lt;/span&gt;
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/app&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;apk&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;build-base&lt;span class="w"&gt; &lt;/span&gt;libpq&lt;span class="w"&gt; &lt;/span&gt;libpq-dev
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;python&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;venv&lt;span class="w"&gt; &lt;/span&gt;/venv&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/venv/bin/python&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;--no-cache-dir&lt;span class="w"&gt; &lt;/span&gt;-U&lt;span class="w"&gt; &lt;/span&gt;pip
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;requirements.txt&lt;span class="w"&gt; &lt;/span&gt;/app
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/venv/bin/pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;--no-cache-dir&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;requirements.txt
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;nikolausers&lt;span class="w"&gt; &lt;/span&gt;/app/nikolausers
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sites&lt;span class="w"&gt; &lt;/span&gt;/app/sites
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;templates&lt;span class="w"&gt; &lt;/span&gt;/app/templates
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;manage.py&lt;span class="w"&gt; &lt;/span&gt;docker/docker-entrypoint.sh&lt;span class="w"&gt; &lt;/span&gt;/app/
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;chmod&lt;span class="w"&gt; &lt;/span&gt;+x&lt;span class="w"&gt; &lt;/span&gt;/app/docker-entrypoint.sh

&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;python:3.14-alpine&lt;/span&gt;
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/app&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;apk&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;libpq
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--from&lt;span class="o"&gt;=&lt;/span&gt;build&lt;span class="w"&gt; &lt;/span&gt;/venv&lt;span class="w"&gt; &lt;/span&gt;/venv
&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--from&lt;span class="o"&gt;=&lt;/span&gt;build&lt;span class="w"&gt; &lt;/span&gt;/app&lt;span class="w"&gt; &lt;/span&gt;/app
&lt;span class="k"&gt;ENTRYPOINT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"/app/docker-entrypoint.sh"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;docker-entrypoint.sh&lt;/h3&gt;
&lt;p&gt;The entrypoint is fairly simple as well. Before starting gunicorn, we need to run migrations and collect static files. To avoid repeating this on container restarts, we create a marker file inside the container to indicate whether setup has already completed. I use three workers, which should be enough for those sites.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="ch"&gt;#!/bin/sh&lt;/span&gt;
&lt;span class="nv"&gt;statefile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/tmp/migrated
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;!&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$statefile&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;/venv/bin/python&lt;span class="w"&gt; &lt;/span&gt;manage.py&lt;span class="w"&gt; &lt;/span&gt;collectstatic&lt;span class="w"&gt; &lt;/span&gt;--noinput
&lt;span class="w"&gt;    &lt;/span&gt;/venv/bin/python&lt;span class="w"&gt; &lt;/span&gt;manage.py&lt;span class="w"&gt; &lt;/span&gt;migrate&lt;span class="w"&gt; &lt;/span&gt;--noinput
&lt;span class="w"&gt;    &lt;/span&gt;touch&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$statefile&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="nb"&gt;exec&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/venv/bin/python&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;gunicorn&lt;span class="w"&gt; &lt;/span&gt;--bind&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:6868&lt;span class="w"&gt; &lt;/span&gt;nikolausers.asgi:application&lt;span class="w"&gt; &lt;/span&gt;-k&lt;span class="w"&gt; &lt;/span&gt;uvicorn_worker.UvicornWorker&lt;span class="w"&gt; &lt;/span&gt;-w&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;docker-compose.yml&lt;/h3&gt;
&lt;p&gt;I mentioned that only one service runs inside Docker, since nginx and PostgreSQL live outside. Docker Compose may feel unnecessary with just one service, but it is still a convenient way to keep the required configuration in a file.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;services:
&lt;span class="w"&gt;  &lt;/span&gt;nikolausers:
&lt;span class="w"&gt;    &lt;/span&gt;restart:&lt;span class="w"&gt; &lt;/span&gt;unless-stopped
&lt;span class="w"&gt;    &lt;/span&gt;image:&lt;span class="w"&gt; &lt;/span&gt;nikolausers:latest
&lt;span class="w"&gt;    &lt;/span&gt;ports:
&lt;span class="w"&gt;      &lt;/span&gt;-&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;127&lt;/span&gt;.0.0.1:6868:6868
&lt;span class="w"&gt;    &lt;/span&gt;user:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"33:33"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# www-data on Debian&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;environment:
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;#SECRET_KEY: ""&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;#DB_NAME: ""&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;#DB_USER: ""&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;#DB_PASSWORD: ""&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;#DB_HOST: ""&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;#EMAIL_HOST: ""&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;volumes:
&lt;span class="w"&gt;      &lt;/span&gt;-&lt;span class="w"&gt; &lt;/span&gt;./static:/app/static
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;nginx&lt;/h3&gt;
&lt;p&gt;The nginx configuration is as simple as it gets:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;server&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# skip standard host config...&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kn"&gt;location&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kn"&gt;proxy_pass&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;http://127.0.0.1:6868/&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kn"&gt;include&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;proxy_params&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kn"&gt;location&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kn"&gt;alias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/srv/users.getnikola.com/static&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In just two evenings, I got rid of the venv and system Python maintenance burden. When I upgrade to Ubuntu 26.04 in a few months, my Python apps will just work with no extra steps needed. Docker is a lot of fun.&lt;/p&gt;</description><category>Django</category><category>Docker</category><category>gunicorn</category><category>Internet</category><category>Linux</category><category>nginx</category><category>Python</category><guid>https://chriswarrick.com/blog/2026/02/06/deploying-python-web-applications-with-docker/</guid><pubDate>Fri, 06 Feb 2026 19:45:00 GMT</pubDate></item><item><title>Distro Hopping, Server Edition</title><link>https://chriswarrick.com/blog/2025/11/09/distro-hopping-server-edition/</link><dc:creator>Chris Warrick</dc:creator><description>&lt;p&gt;I’ve recently migrated my VPS from Fedora to Ubuntu. Here’s a list of things that might be useful to keep in mind before, during, and after a migration of a server that hosts publicly accessible Web sites and applications, as well as other personal services, and how to get rid of the most annoying parts of Ubuntu.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h2&gt;Why switch?&lt;/h2&gt;
&lt;p&gt;Fedora is a relatively popular distro, so it’s well supported by software vendors. Its packagers adopt a no-nonsense approach, making very little changes that deviate from the upstream.&lt;/p&gt;
&lt;p&gt;Ubuntu is not my favorite distro, far from it. While it is perhaps the most popular distro out there, its packages contain many more patches compared to Fedora, and Canonical (the company behind Ubuntu) are famous for betting on the wrong horse (Unity, upstart, Mir…). But one thing Ubuntu does well is stability. Fedora makes releases every 6 months, and those releases are supported for just 13 months, which means upgrading at least every year. Every upgrade may introduce incompatibilities, almost every upgrade requires recreating Python venvs. That gets boring fast, and it does not necessarily bring benefits. Granted, the Fedora system upgrade works quite well, and I upgraded through at least eight releases without a re-install, but I would still prefer to avoid it. That’s why I went with Ubuntu LTS, which is supported for five years, with a new release every two years, but which still comes with reasonably new software (and with many third-party repositories if something is missing or outdated).&lt;/p&gt;
&lt;h2&gt;Test your backups&lt;/h2&gt;
&lt;p&gt;I have a backup “system” that’s a bunch of Bash scripts. After upgrading one of the services that is being backed up, the responsible script started crashing, and thus backups stopped working. Another thing that broke was e-mails from cron, so I didn’t know anything was wrong.&lt;/p&gt;
&lt;p&gt;While I do have full disk backups enabled at &lt;a href="https://hetzner.cloud/?ref=Qy1lehF8PwzP"&gt;Hetzner&lt;/a&gt; &lt;em&gt;(disclaimer: referral link)&lt;/em&gt;, my custom backups are more fine-grained (e.g. important configuration files, database dumps, package lists), so they are quite useful in migrating between OSes.&lt;/p&gt;
&lt;p&gt;So, here’s a reminder not only to test your backups regularly, but also to make sure they are being created at all, and to make sure cron can send you logs somewhere you can see them.&lt;/p&gt;
&lt;p&gt;Bonus cron tip: set &lt;code&gt;MAILFROM=&lt;/code&gt; and &lt;code&gt;MAILTO=&lt;/code&gt; in your crontab if your SMTP server does not like the values cron uses by default.&lt;/p&gt;
&lt;h2&gt;Think about IP address reassignment (or pray to the DNS gods)&lt;/h2&gt;
&lt;p&gt;A new VPS or cloud server probably means a new IP address. But if you get a new IP address, that might complicate the migration of your publicly accessible applications. If you’re proxying all your Web properties through Cloudflare or something similar, that’s probably not an issue. But if you have a raw A record somewhere, things can get complicated. DNS servers and operating systems do a lot of caching. The conventional wisdom is to wait 24 or even 48 hours after changing DNS values. This might be true if your TTL is set to a long value, but if your TTL is short, the only worry are DNS servers that ignore TTL values and cache records for longer. If you plan a migration, it’s good to check your TTL well in advance, and not worry too much about broken DNS servers.&lt;/p&gt;
&lt;p&gt;But you might not need a new IP. Carefully review your cloud provider’s IP management options before making any changes. Hetzner is more flexible than other hosts in this regard, as it is possible to &lt;a href="https://docs.hetzner.com/cloud/servers/primary-ips/faq"&gt;move primary public IP addresses (not “floating” or “elastic” IPs) between servers&lt;/a&gt;, as long as you’re okay with a few minutes’ downtime (you will need to shut down the source and destination servers).&lt;/p&gt;
&lt;p&gt;If you’re not okay with any downtime, you would probably want to leverage the floating/elastic IP feature, or hope DNS propagates quickly enough.&lt;/p&gt;
&lt;h2&gt;Trim the fat&lt;/h2&gt;
&lt;p&gt;My VPS ran a lot of services I don’t need anymore, but never really got around to decommissioning. For example, I had a full Xfce install with VNC access (the VNC server was only running when needed). I haven’t actually used the desktop for ages, so I just dropped it.&lt;/p&gt;
&lt;p&gt;I also had an OpenVPN setup. It was useful years ago, when mobile data allowances were much smaller and speeds much worse. These days, I don’t use public WiFi networks at all, unless I’m going abroad, and I just buy one month of &lt;a href="https://mullvad.net/"&gt;Mullvad VPN&lt;/a&gt; for €5 whenever that happens. So, add another service to the “do not migrate” list.&lt;/p&gt;
&lt;p&gt;One thing that I could not just remove was the e-mail server. Many years ago, I ran a reasonably functional e-mail server on my VPS. I’ve since then migrated to &lt;a href="https://www.zoho.com/mail/"&gt;Zoho Mail&lt;/a&gt; (which costs €10.80/year), in part due to IP reputation issues after changing hosting providers, and also to avoid having to fight spam. When I did that, I kept Postfix around, but as a local server for things like cron or Django to send e-mail with, and I configured it to send all e-mails via Zoho. But I did not really want to move over all the configuration, hoping that Ubuntu’s Postfix packages can work with my hacked together config from Fedora. So I replaced the server with &lt;a href="https://www.opensmtpd.org/"&gt;OpenSMTPD&lt;/a&gt; (from the OpenBSD project), and all the Postfix configuration files with just one short configuration file:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;table aliases file:/etc/aliases
table secrets file:/etc/mail-secrets

listen on localhost
listen on 172.17.0.1 # Docker

action "relay" relay host smtp+tls://smtp@smtp.example.net:587 auth &amp;lt;secrets&amp;gt; mail-from "@example.com"

match from any for any action "relay"
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Dockerize everything…&lt;/h2&gt;
&lt;p&gt;My server runs a few different apps, some of which are exposed on the public Internet, while some do useful work in the background. The services I have set up most recently are containerized with the help of Docker. The only Docker-based service that was stateful (and did not just use folders mounted as volumes) was a MariaDB database. Migrating that is straightforward with a simple dump-and-restore.&lt;/p&gt;
&lt;p&gt;Of course, not everything on my server is in Docker. The public-facing nginx install isn’t, and neither is PostgreSQL (but that was also a quick dump-and-restore migration with some extra steps).&lt;/p&gt;
&lt;h2&gt;…especially Python&lt;/h2&gt;
&lt;p&gt;But then, there are the Python apps. Python the language is cool (if a little slow), but the packaging story is a &lt;a href="https://chriswarrick.com/blog/2023/01/15/how-to-improve-python-packaging/"&gt;total&lt;/a&gt; dumpster &lt;a href="https://chriswarrick.com/blog/2024/01/15/python-packaging-one-year-later/"&gt;fire&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;By the way, here’s a quick recap of 2024/2025 in Python packaging: the most hyped Python package manager (&lt;code&gt;uv&lt;/code&gt;) is written in Rust, which screams “Python is a toy language in which you can’t even write a tool as simple as a package manager”. (I know, dependency resolution is computationally expensive, so doing &lt;em&gt;that&lt;/em&gt; in Rust makes sense, but everything else could easily be done in pure Python. And no, the package manager should not manage Python installs.) Of course, almost all the other contenders listed in my 2023 post are still being developed. On the standards front, the community finally produced a lockfile standard after years of discussions.&lt;/p&gt;
&lt;p&gt;Anyway, I have three Python apps. One of them is &lt;a href="https://isso-comments.de/"&gt;Isso&lt;/a&gt;, which is providing the comments box below this post. I used to run a modified version of Isso a long time ago, but I don’t need to anymore. I looked at the docs, and they offer &lt;a href="https://isso-comments.de/docs/reference/installation/#using-docker"&gt;a pre-built Docker image&lt;/a&gt;, which means I could just quickly deploy it on my server with Docker and skip the pain of managing Python environments.&lt;/p&gt;
&lt;p&gt;The other two apps are Django projects built by yours truly. They are not containerized, they exist in venvs created using the system Python. Moving venvs between machines is generally impossible, so I had to re-create them. Of course, I hit a deprecation, because the Python maintainers (especially in the packaging world) does not understand their responsibility as maintainers of the most popular programming language. This time, it was caused by &lt;a href="https://github.com/pypa/pip/issues/11457"&gt;an old editable install with setuptools (using setup.py develop, not PEP 660)&lt;/a&gt;, and installs with more recent pip/setuptools versions would not have this error… although &lt;a href="https://discuss.python.org/t/do-we-want-to-keep-the-build-system-default-for-pyproject-toml/104759"&gt;some people want to remove the fallback to setuptools if there is no pyproject.toml&lt;/a&gt;, so you need to stay up to date with the whims of the Python packaging industry if you want to use Python software.&lt;/p&gt;
&lt;h2&gt;Don’t bother with ufw&lt;/h2&gt;
&lt;p&gt;Ubuntu ships with &lt;code&gt;ufw&lt;/code&gt;, the “uncomplicated firewall”, in the default install. I was previously using &lt;code&gt;firewalld&lt;/code&gt;, a Red Hat-adjacent project, but I decided to give ufw a try. Since if it’s part of the default install, it might be supported better by the system.&lt;/p&gt;
&lt;p&gt;It turns out that Docker and ufw &lt;a href="https://docs.docker.com/engine/network/packet-filtering-firewalls/#docker-and-ufw"&gt;don’t play together&lt;/a&gt;. &lt;a href="https://github.com/chaifeng/ufw-docker?tab=readme-ov-file#solving-ufw-and-docker-issues"&gt;Someone has built a set of rules that are supposed to fix it&lt;/a&gt;, but that did not work for me.&lt;/p&gt;
&lt;p&gt;Docker &lt;a href="https://docs.docker.com/engine/network/packet-filtering-firewalls/#integration-with-firewalld"&gt;does integrate with firewalld&lt;/a&gt;, and Ubuntu has packages for it, so I just installed it, enabled the services that need to be publicly available and things were working again.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update (2025-11-23):&lt;/em&gt; The iptables integration was not very stable on my Ubuntu system, so I disabled the iptables integration and switched to &lt;a href="https://dev.to/soerenmetje/how-to-secure-a-docker-host-using-firewalld-2joo"&gt;a simpler config in firewalld only&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Kill the ads (and other nonsense too)&lt;/h2&gt;
&lt;p&gt;Red Hat makes money by selling a stable OS with at least 10 years of support to enterprises, and their free offering is Fedora, with just 13 months of support; RHEL releases are branched off from Fedora. SUSE also sells SUSE Linux Enterprise and has openSUSE as the free offering (but the relationship between the paid and free version is more complicated).&lt;/p&gt;
&lt;p&gt;Ubuntu chose a different monetization strategy: the enterprise offering is the same OS as the free offering, but it gets extra packages and extra updates. The free OS advertises the paid services. It is fairly simple to get rid of them all:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;sudo apt autoremove ubuntu-pro-client
sudo chmod -x /etc/update-motd.d/*
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Also, Ubuntu installs snap by default. Snap is a terrible idea. Luckily, there are no snaps installed by default on a Server install, so we can just remove &lt;code&gt;snapd&lt;/code&gt;. We’ll also remove &lt;code&gt;lxd-installer&lt;/code&gt; to save ~25 kB of disk space, since the installer requires snap, and lxd is another unsuccessful Canonical project.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;sudo apt autoremove snapd lxd-installer
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;The cost of downgrading&lt;/h2&gt;
&lt;p&gt;Going from Fedora 42 (April 2025) to Ubuntu 24.04 (April 2024) means some software will be downgraded in the process. In general, this does not matter, as most software does not mind downgrades as much. One notable exception is WeeChat, the IRC client, whose config files are versioned, and Ubuntu’s version is not compatible with the one in Fedora. But here’s where Ubuntu’s popularity shines: &lt;a href="https://weechat.org/download/debian/"&gt;WeeChat has its own repositories for Debian and Ubuntu&lt;/a&gt;, so I could just get the latest version without building it myself or trying to steal packages from a newer version.&lt;/p&gt;
&lt;p&gt;Other than WeeChat, I haven’t experienced any other issues with software due to a downgrade. Some of it is luck (or not using new/advanced features), some of it is software caring about backwards compatibility.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Was it worth it? Time will tell. Upgrading Fedora itself was not that hard, and I expect Ubuntu upgrades to be OK too — the annoying part was cleaning up and getting things to work after the upgrade, and the switch means I will have to do it only every 2-4 years instead of every 6-12 months.&lt;/p&gt;
&lt;p&gt;The switchover took a few hours, especially since I didn’t have much up-to-date documentation of what is actually installed and running, and there are always the minor details where distros differ that may require adjusting to. I think a migration like this is worth trying if rolling-release or frequently-released distros are too unstable for your needs.&lt;/p&gt;</description><category>Django</category><category>Docker</category><category>Fedora</category><category>Linux</category><category>Python</category><category>Ubuntu</category><guid>https://chriswarrick.com/blog/2025/11/09/distro-hopping-server-edition/</guid><pubDate>Sun, 09 Nov 2025 18:00:00 GMT</pubDate></item></channel></rss>